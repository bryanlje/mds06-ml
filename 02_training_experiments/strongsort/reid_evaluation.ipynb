{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy motmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzqBpc-aH_4o",
        "outputId": "11fe4d24-3ab8-49f9-e8ab-fe164458a4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.3.3\n",
            "Uninstalling numpy-2.3.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/numpy-config\n",
            "    /usr/local/lib/python3.12/dist-packages/numpy-2.3.3.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.12/dist-packages/numpy.libs/libscipy_openblas64_-8fb3d286.so\n",
            "    /usr/local/lib/python3.12/dist-packages/numpy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled numpy-2.3.3\n",
            "Found existing installation: motmetrics 1.4.0\n",
            "Uninstalling motmetrics-1.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.12/dist-packages/motmetrics-1.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.12/dist-packages/motmetrics/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled motmetrics-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I44u8eYnKBhP",
        "outputId": "9a5e7098-7f7b-4a83-d6cb-dfa35026ab23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy==2.0.2\"\n",
        "!pip install git+https://github.com/cheind/py-motmetrics.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJhYRMciKYYF",
        "outputId": "40460fd1-34d1-4afe-fcf6-5d29a723021e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting git+https://github.com/cheind/py-motmetrics.git\n",
            "  Cloning https://github.com/cheind/py-motmetrics.git to /tmp/pip-req-build-lertffjq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cheind/py-motmetrics.git /tmp/pip-req-build-lertffjq\n",
            "  Resolved https://github.com/cheind/py-motmetrics.git to commit 057504b5bc6c8e9b1ef336e76cb6adcfbd30f7b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.12/dist-packages (from motmetrics==1.4.0) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.12/dist-packages (from motmetrics==1.4.0) (2.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from motmetrics==1.4.0) (1.16.2)\n",
            "Requirement already satisfied: xmltodict>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from motmetrics==1.4.0) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.1->motmetrics==1.4.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.1->motmetrics==1.4.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23.1->motmetrics==1.4.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.1->motmetrics==1.4.0) (1.17.0)\n",
            "Building wheels for collected packages: motmetrics\n",
            "  Building wheel for motmetrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for motmetrics: filename=motmetrics-1.4.0-py3-none-any.whl size=165446 sha256=831e3291958f9970b5068eefe38dea9cc87e9aec964a1a83703da4293655efe1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sbjaan8o/wheels/14/94/6d/502b7fd4aad7a8626b6d46dc95f53655b23a80931e7a34d650\n",
            "Successfully built motmetrics\n",
            "Installing collected packages: motmetrics\n",
            "Successfully installed motmetrics-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import motmetrics as mm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6vDoq7_mHTyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(gt_file, pred_file):\n",
        "    \"\"\"\n",
        "    Calculates MOTA and IDF1 scores given ground truth and prediction files.\n",
        "    \"\"\"\n",
        "    # 1. Load the data using pandas\n",
        "    gt_df = pd.read_csv(gt_file, header=None)\n",
        "    pred_df = pd.read_csv(pred_file)\n",
        "\n",
        "    # 2. Create an accumulator\n",
        "    acc = mm.MOTAccumulator(auto_id=True)\n",
        "\n",
        "    # --- FIX: Iterate over all unique frames from both GT and Predictions ---\n",
        "    all_frames = sorted(list(set(gt_df[0].unique()) | set(pred_df['frame'].unique())))\n",
        "\n",
        "    for frame_id in all_frames:\n",
        "        # Get ground truth for the current frame (if it exists)\n",
        "        gt_frame = gt_df[gt_df[0] == frame_id]\n",
        "        if not gt_frame.empty:\n",
        "            gt_ids = gt_frame[1].values\n",
        "            gt_boxes = gt_frame[[2, 3, 4, 5]].values  # Format: [x, y, w, h]\n",
        "        else:\n",
        "            gt_ids = np.array([])\n",
        "            gt_boxes = np.empty((0, 4))\n",
        "\n",
        "        # Get predictions for the current frame (if it exists)\n",
        "        pred_frame = pred_df[pred_df['frame'] == frame_id]\n",
        "        if not pred_frame.empty:\n",
        "            pred_ids = pred_frame['id'].values\n",
        "            # Convert predictions from [x1, y1, x2, y2] to [x, y, w, h]\n",
        "            pred_boxes = np.stack([\n",
        "                pred_frame['x1'],\n",
        "                pred_frame['y1'],\n",
        "                pred_frame['x2'] - pred_frame['x1'],\n",
        "                pred_frame['y2'] - pred_frame['y1']\n",
        "            ], axis=1)\n",
        "        else:\n",
        "            pred_ids = np.array([])\n",
        "            pred_boxes = np.empty((0, 4))\n",
        "\n",
        "        # print(gt_boxes)\n",
        "        # print(pred_boxes)\n",
        "        # print()\n",
        "        # 4. Calculate the distance matrix (IoU)\n",
        "        distance_matrix = mm.distances.iou_matrix(gt_boxes, pred_boxes, max_iou=0.9)\n",
        "\n",
        "        # 5. Update the accumulator for the current frame\n",
        "        acc.update(gt_ids, pred_ids, distance_matrix)\n",
        "\n",
        "    # 6. Compute and display the final metrics\n",
        "    mh = mm.metrics.create()\n",
        "    summary = mh.compute(acc, metrics=['mota', 'idf1'], name='acc_summary')\n",
        "    print(mm.io.render_summary(\n",
        "        summary,\n",
        "        formatters=mh.formatters,\n",
        "        namemap=mm.io.motchallenge_metric_names\n",
        "    ))"
      ],
      "metadata": {
        "id": "fbDwJ7wEHVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt_file_path = 'phua_vid_1.txt'\n",
        "pred_file_path = 'phua_vid_1 annotated.csv'\n",
        "\n",
        "calculate_metrics(gt_file_path, pred_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA8rPSJ9HX4Z",
        "outputId": "6cf86021-9c1d-4aa7-becf-1587e846b001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             MOTA  IDF1\n",
            "acc_summary 51.0% 60.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Configuration ---\n",
        "# Replace with the name of your CSV file\n",
        "input_filename = '/content/phua_vid_3 annotated.csv'\n",
        "# The name of the new file that will be created\n",
        "output_filename = '/content/phua_vid_3 reordered.csv'\n",
        "\n",
        "# --- Script ---\n",
        "try:\n",
        "    # Read the original CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(input_filename)\n",
        "    print(f\"Successfully loaded '{input_filename}'.\")\n",
        "\n",
        "    # Create a list to hold the reordered data for each frame\n",
        "    reordered_frames = []\n",
        "\n",
        "    # Group the DataFrame by the 'frame' column and iterate through each frame\n",
        "    for frame_num, frame_group in df.groupby('frame'):\n",
        "\n",
        "        # Find the specific rows for ID 1 and ID 2\n",
        "        row_id1 = frame_group[frame_group['id'] == 1]\n",
        "        row_id2 = frame_group[frame_group['id'] == 2]\n",
        "\n",
        "        # Select all other rows that are not ID 1 or 2\n",
        "        other_rows = frame_group[~frame_group['id'].isin([1, 2])]\n",
        "\n",
        "        # Check if both ID 1 and ID 2 exist in this frame to perform the swap\n",
        "        if not row_id1.empty and not row_id2.empty:\n",
        "            # Concatenate in the desired order: ID 1, then ID 2, then others\n",
        "            new_frame_order = pd.concat([row_id1, row_id2, other_rows])\n",
        "            reordered_frames.append(new_frame_order)\n",
        "        else:\n",
        "            # If one or both are missing, just keep the original order for that frame\n",
        "            reordered_frames.append(frame_group)\n",
        "\n",
        "    # Combine all the reordered frames back into a single DataFrame\n",
        "    final_df = pd.concat(reordered_frames)\n",
        "\n",
        "    # Save the final DataFrame to a new CSV file, without the extra index column\n",
        "    final_df.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(f\"✅ Success! The reordered data has been saved to '{output_filename}'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: The file '{input_filename}' was not found. Please make sure it's in the same directory as the script.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccr_c2MmHe6M",
        "outputId": "dd2e0ab5-1caf-4468-9dbb-ee896cdc1802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded '/content/phua_vid_3 annotated.csv'.\n",
            "✅ Success! The reordered data has been saved to '/content/phua_vid_3 reordered.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZD6kntyTE0p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}