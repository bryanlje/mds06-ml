{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h5cTXHLtJGES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce328016-8f5b-40b7-9cbf-b60439a920cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/13.6 MB\u001b[0m \u001b[31m193.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m223.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m223.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install ultralytics decord tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np, cv2, math, csv, os\n",
        "from decord import VideoReader, cpu\n",
        "from tqdm import tqdm\n",
        "import librosa"
      ],
      "metadata": {
        "id": "-ziMQw9hQwQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c00d5f3-406a-4b84-b653-a7e7e4622acd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jFlWfIQXhSqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6d7941-bc01-4001-82b4-64f17c749640"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "POSE_MODEL = \"yolo11n-pose.pt\"  # small & fast\n",
        "model = YOLO(POSE_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJM59F10TMIO",
        "outputId": "43af1ffa-2cd1-4705-8f63-0e093e6a8233"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt': 100% ━━━━━━━━━━━━ 6.0MB 85.3MB/s 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, k=5):\n",
        "    if len(x)==0: return x\n",
        "    k = max(1,k)\n",
        "    return np.convolve(x, np.ones(k)/k, mode='same')\n",
        "\n",
        "def wrist_velocity_series(kpts):\n",
        "    \"\"\"\n",
        "    kpts: T x J x 2   (xy only; use conf if you want)\n",
        "    J: COCO-style 17 (Ultralytics uses COCO keypoints)\n",
        "    wristL, wristR indices (COCO): 9 and 10; elbow 7/8; shoulder 5/6\n",
        "    \"\"\"\n",
        "    Wl, Wr = 9, 10\n",
        "    # choose per-frame faster wrist as proxy for racket hand\n",
        "    v = []\n",
        "    for t in range(1, len(kpts)):\n",
        "        dl = np.linalg.norm(kpts[t, Wl]-kpts[t-1, Wl])\n",
        "        dr = np.linalg.norm(kpts[t, Wr]-kpts[t-1, Wr])\n",
        "        v.append(max(dl, dr))\n",
        "    v = np.array([v[0]] + v)  # pad\n",
        "    return smooth(v, k=7)\n",
        "\n",
        "def elbow_angle_rate(kpts):\n",
        "    # angle at elbow: shoulder-elbow-wrist\n",
        "    def angle(p, q, r):\n",
        "        v1 = p-q; v2 = r-q\n",
        "        a = np.arctan2(v1[1], v1[0]) - np.arctan2(v2[1], v2[0])\n",
        "        return np.abs((a+np.pi)%(2*np.pi)-np.pi)\n",
        "    Ls, Le, Lw = 5,7,9\n",
        "    Rs, Re, Rw = 6,8,10\n",
        "    ang=[]\n",
        "    for t in range(len(kpts)):\n",
        "        aL = angle(kpts[t,Ls], kpts[t,Le], kpts[t,Lw])\n",
        "        aR = angle(kpts[t,Rs], kpts[t,Re], kpts[t,Rw])\n",
        "        ang.append(max(aL,aR))\n",
        "    ang = np.array(ang)\n",
        "    d_ang = np.abs(np.diff(ang,prepend=ang[0]))\n",
        "    return smooth(d_ang, k=7)\n",
        "\n",
        "def nms_peaks(sig, min_dist=12, thr=0.8):\n",
        "    idx = []\n",
        "    last = -999\n",
        "    mx = sig.max() if len(sig)>0 else 1.0\n",
        "    for i in range(2, len(sig)-2):\n",
        "        if sig[i] > sig[i-1] and sig[i] > sig[i+1] and sig[i] > thr*mx and i-last>=min_dist:\n",
        "            idx.append(i); last = i\n",
        "    return idx"
      ],
      "metadata": {
        "id": "QelrUDFBfJUC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def propose_contacts_for_video(proxy_path, audio_boost=True):\n",
        "    vr = VideoReader(proxy_path, ctx=cpu(0))\n",
        "    fps = float(vr.get_avg_fps()) if hasattr(vr, 'get_avg_fps') else 30.0\n",
        "    T = len(vr)\n",
        "    print('reached here')\n",
        "\n",
        "    # run pose in batches\n",
        "    boxes = []\n",
        "    keyseq = []  # T x players x J x 2\n",
        "    for i in tqdm(range(T), desc=\"pose\"):\n",
        "        frame = vr[i].asnumpy()\n",
        "        res = model.predict(frame, verbose=False)[0]\n",
        "\n",
        "        # pick top 2 person detections by conf/area\n",
        "        dets=[]\n",
        "        for b, k in zip(res.boxes, res.keypoints):\n",
        "            if int(b.cls.item())!=0:  # 0=person for COCO\n",
        "                continue\n",
        "            x1,y1,x2,y2 = map(float, b.xyxy[0].tolist())\n",
        "            conf = float(b.conf[0])\n",
        "            area = (x2-x1)*(y2-y1)\n",
        "            kxy = k.xy[0].cpu().numpy()[:,:2]  # J x 2\n",
        "            dets.append((conf*area, kxy))\n",
        "\n",
        "        dets = sorted(dets, key=lambda x:-x[0])[:4]\n",
        "\n",
        "        # Ensure the array always has a consistent shape (2 players)\n",
        "        frame_kpts = [d[1] for d in dets]\n",
        "        # Pad with a zero array for a dummy player if less than 2 players are detected\n",
        "        while len(frame_kpts) < 4:\n",
        "            frame_kpts.append(np.zeros((17, 4)))\n",
        "\n",
        "        keyseq.append(np.stack(frame_kpts, axis=0))\n",
        "\n",
        "    keyseq = np.array(keyseq, dtype=np.float32)  # T x P x J x 2\n",
        "\n",
        "    # aggregate per player (or max over players per frame)\n",
        "    v_max=[]; a_max=[]\n",
        "    for p in range(min(2, keyseq.shape[1])):\n",
        "        v = wrist_velocity_series(keyseq[:,p])\n",
        "        a = elbow_angle_rate(keyseq[:,p])\n",
        "        v_max.append(v); a_max.append(a)\n",
        "\n",
        "    # Handle the case where no players were detected at all\n",
        "    if not v_max:\n",
        "        return [], fps\n",
        "\n",
        "    v_max = np.max(np.stack(v_max,axis=0), axis=0)\n",
        "    a_max = np.max(np.stack(a_max,axis=0), axis=0)\n",
        "\n",
        "    sig = smooth((v_max * a_max), k=5)\n",
        "    peaks = nms_peaks(sig, min_dist=int(0.4*fps), thr=0.55)  # ~≥0.4s apart\n",
        "\n",
        "    # optional audio peaks\n",
        "    if audio_boost:\n",
        "        # decode audio and find transients\n",
        "        import tempfile\n",
        "        tmp_wav = \"/content/tmp_audio.wav\"\n",
        "        os.system(f'ffmpeg -y -i \"{proxy_path}\" -vn -ac 1 -ar 16000 -acodec pcm_s16le \"{tmp_wav}\"')\n",
        "        y, sr = librosa.load(tmp_wav, sr=16000)\n",
        "        onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "        onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr, units='time')\n",
        "        audio_frames = set([int(t*fps) for t in onsets])\n",
        "        # keep pose peaks that are near audio peaks\n",
        "        peaks = [p for p in peaks if any(abs(p - af) <= int(0.06*fps) for af in audio_frames)]\n",
        "\n",
        "    return peaks, fps"
      ],
      "metadata": {
        "id": "0injnVA5Fr0r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_proposals_csv(channel, yt_id, peaks, fps):\n",
        "    outdir = f\"{PROPOSALS}/{channel}/{yt_id}\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(f\"{outdir}/proposals.csv\",\"w\",newline=\"\") as f:\n",
        "        w=csv.writer(f); w.writerow([\"frame_idx\",\"t_ms\"])\n",
        "        for p in peaks: w.writerow([p, int(1000*p/fps)])\n",
        "\n",
        "def render_overlay(proxy_path, peaks, out_mp4):\n",
        "    vr = VideoReader(proxy_path, ctx=cpu(0))\n",
        "    fps = 25  # proxies are CFR=30\n",
        "    H,W,_ = vr[0].asnumpy().shape\n",
        "    tmp = \"/content/ov.avi\"\n",
        "    vw = cv2.VideoWriter(tmp, cv2.VideoWriter_fourcc(*\"XVID\"), fps, (W,H))\n",
        "    s=set(peaks)\n",
        "    for i in range(len(vr)):\n",
        "        f = vr[i].asnumpy()\n",
        "        if i in s:\n",
        "            cv2.putText(f, \"PROPOSED CONTACT\", (40,60), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3, cv2.LINE_AA)\n",
        "            cv2.circle(f, (60,90), 12, (0,0,255), -1)\n",
        "        vw.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "    vw.release()\n",
        "    os.system(f'ffmpeg -y -i {tmp} -c:v libx264 -preset veryfast -crf 23 \"{out_mp4}\"')"
      ],
      "metadata": {
        "id": "SQclw6v6Fvb2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Batch through all proxies → save proposals & an overlay for quick QC**"
      ],
      "metadata": {
        "id": "IMjCZFhEFx4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/FIT3163,3164/SlowFast\"\n",
        "PROX = f\"{ROOT}/02_proxy_25fps\"\n",
        "PROPOSALS = f\"{ROOT}/03_pose_proposals\"\n",
        "os.makedirs(PROPOSALS, exist_ok=True)"
      ],
      "metadata": {
        "id": "74HLMq0lPyMJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glob_pattern = os.path.join(PROX, \"*\", \"*\", \"proxy.mp4\")\n",
        "proxy_files = glob.glob(glob_pattern)\n",
        "print(f\"Found {len(proxy_files)} proxy files to process.\")\n",
        "\n",
        "proxy_files = ['/content/drive/MyDrive/FIT3163,3164/SlowFast/02_proxy_25fps/lcw_ld_2016_short/1/proxy.mp4']\n",
        "\n",
        "for proxy in proxy_files:\n",
        "    print(f\"\\n--- Processing file: {proxy} ---\")\n",
        "\n",
        "    try:\n",
        "        # Extract channel and YouTube ID from the file path\n",
        "        path_parts = proxy.split(os.sep)\n",
        "        channel, yt_id = path_parts[-3], path_parts[-2]\n",
        "\n",
        "        # Propose contacts based on pose and audio\n",
        "        print(\"Running pose and audio analysis...\")\n",
        "        peaks, fps = propose_contacts_for_video(proxy, audio_boost=False)\n",
        "        print(f\"Successfully identified {len(peaks)} contact proposals.\")\n",
        "\n",
        "        # Save proposals to CSV\n",
        "        save_proposals_csv(channel, yt_id, peaks, fps)\n",
        "        print(\"CSV file successfully saved.\")\n",
        "\n",
        "        # Render overlay video\n",
        "        out_mp4 = f\"{PROPOSALS}/{channel}/{yt_id}/overlay.mp4\"\n",
        "        if not os.path.exists(out_mp4):\n",
        "            print(f\"Rendering overlay video to {out_mp4}...\")\n",
        "            render_overlay(proxy, peaks, out_mp4)\n",
        "            if os.path.exists(out_mp4):\n",
        "                print(\"Overlay video successfully created.\")\n",
        "            else:\n",
        "                print(\"ERROR: Overlay video was not created. Check for errors in the render_overlay function.\")\n",
        "        else:\n",
        "            print(f\"Overlay video already exists at {out_mp4}. Skipping render.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {proxy}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tegq96LQF5-S",
        "outputId": "dc3c82ec-909f-47e5-c4d6-7de37c4723a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 proxy files to process.\n",
            "\n",
            "--- Processing file: /content/drive/MyDrive/FIT3163,3164/SlowFast/02_proxy_25fps/lcw_ld_2016_short/1/proxy.mp4 ---\n",
            "Running pose and audio analysis...\n",
            "reached here\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pose:   0%|          | 0/2752 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while processing /content/drive/MyDrive/FIT3163,3164/SlowFast/02_proxy_25fps/lcw_ld_2016_short/1/proxy.mp4: all input arrays must have the same shape\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27A3VgqrP67I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}