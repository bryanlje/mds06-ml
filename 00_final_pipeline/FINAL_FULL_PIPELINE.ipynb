{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e421951497af4ad68563f5fce002c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ba61b9819ff4a59b53c8e5c79805500",
              "IPY_MODEL_59be82313ef0413c99958af64840d162",
              "IPY_MODEL_a71bf54efca14fe6a359ea96a2ef9df1"
            ],
            "layout": "IPY_MODEL_20e8feaa268a4f348c4f8a7704fc8cb7"
          }
        },
        "0ba61b9819ff4a59b53c8e5c79805500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5eae1a4954417d9c07c28abfb7d607",
            "placeholder": "​",
            "style": "IPY_MODEL_50694922114e49b5adb5d68c502df692",
            "value": "100%"
          }
        },
        "59be82313ef0413c99958af64840d162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e727e9b4a1354ca7b9f374912d38d4fc",
            "max": 781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04c74175973346eaa8494a1dc3519ac3",
            "value": 781
          }
        },
        "a71bf54efca14fe6a359ea96a2ef9df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b926eaa2e9c41c5a820d9e38b85ea74",
            "placeholder": "​",
            "style": "IPY_MODEL_e90ae29c46424a1ba64945c563284fed",
            "value": " 781/781 [00:59&lt;00:00, 14.15frame/s]"
          }
        },
        "20e8feaa268a4f348c4f8a7704fc8cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5eae1a4954417d9c07c28abfb7d607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50694922114e49b5adb5d68c502df692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e727e9b4a1354ca7b9f374912d38d4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c74175973346eaa8494a1dc3519ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b926eaa2e9c41c5a820d9e38b85ea74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90ae29c46424a1ba64945c563284fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4802404be664e7ca30435b36fc874a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39f89962b3a44358aea345a98d8bd3c0",
              "IPY_MODEL_da43458b0e0f4a23ae96d375004d0437",
              "IPY_MODEL_e3dda69b7615416ea0b01292e6a52862"
            ],
            "layout": "IPY_MODEL_e3c11bc10e7e4349b3ac724ded426953"
          }
        },
        "39f89962b3a44358aea345a98d8bd3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3050f66ac034ca1a4189eb14e3cbf6a",
            "placeholder": "​",
            "style": "IPY_MODEL_2d03d715b7b4403bba0f14f3eacadd5e",
            "value": "Pre-fetching frames: 100%"
          }
        },
        "da43458b0e0f4a23ae96d375004d0437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a38122064e479097ad0c47e0132d39",
            "max": 646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6549bc47949445dfa7b5623e1eaf0909",
            "value": 646
          }
        },
        "e3dda69b7615416ea0b01292e6a52862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca2063eadf14776b50e15c8c9e1a6b4",
            "placeholder": "​",
            "style": "IPY_MODEL_4f1f1b7315a240c4b39f99e3306c2867",
            "value": " 646/646 [00:34&lt;00:00, 18.87it/s]"
          }
        },
        "e3c11bc10e7e4349b3ac724ded426953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3050f66ac034ca1a4189eb14e3cbf6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d03d715b7b4403bba0f14f3eacadd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5a38122064e479097ad0c47e0132d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6549bc47949445dfa7b5623e1eaf0909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dca2063eadf14776b50e15c8c9e1a6b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1f1b7315a240c4b39f99e3306c2867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20bd0b26c41848be87edcc1e7fbeacc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06fb82a5d714432d81d15a02e138c4c9",
              "IPY_MODEL_ae7d3e5efb9c467389e5c70bbfe27ffe",
              "IPY_MODEL_16532d8a911b41198ed017f94f422aca"
            ],
            "layout": "IPY_MODEL_a867fae6401045558b661aaaf37b705d"
          }
        },
        "06fb82a5d714432d81d15a02e138c4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64fdbd30b76046558b076576c3f92bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_acd20d97df7144ca9f81fd55a0c9678f",
            "value": "Processing contact frames: 100%"
          }
        },
        "ae7d3e5efb9c467389e5c70bbfe27ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd30ccf762ac405287c26e96b4f10d10",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9056b47d54e94ccc86b083df27a2f2c6",
            "value": 26
          }
        },
        "16532d8a911b41198ed017f94f422aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1192c2b0323a444bac80cf6f7c863db2",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7d45c2486c42b8a44047c79c514cca",
            "value": " 26/26 [00:05&lt;00:00,  4.82it/s]"
          }
        },
        "a867fae6401045558b661aaaf37b705d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64fdbd30b76046558b076576c3f92bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd20d97df7144ca9f81fd55a0c9678f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd30ccf762ac405287c26e96b4f10d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9056b47d54e94ccc86b083df27a2f2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1192c2b0323a444bac80cf6f7c863db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7d45c2486c42b8a44047c79c514cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f613b2a8e9b45989019d17cef448530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42ef43bbe9fc4ad0917e63f984b99c7a",
              "IPY_MODEL_c11fdcdadee14e6aa7878b10eccf520d",
              "IPY_MODEL_88bd04e814904fee8e6e8d3809d5d356"
            ],
            "layout": "IPY_MODEL_e0f314af2d3c40dcb58b7e3ffc92ad7f"
          }
        },
        "42ef43bbe9fc4ad0917e63f984b99c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1783a2c37e498885289bbece8e1b58",
            "placeholder": "​",
            "style": "IPY_MODEL_f5cdf616c09642e787ecf1913da28269",
            "value": "Writing video: "
          }
        },
        "c11fdcdadee14e6aa7878b10eccf520d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_687aad7ea841415da1053adb80c40b06",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_018666e97f244a23917460bd47df124e",
            "value": 1
          }
        },
        "88bd04e814904fee8e6e8d3809d5d356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c3360ba7724ccface54b3535ac7fc1",
            "placeholder": "​",
            "style": "IPY_MODEL_3892b85f37164ed28bca0eba8cdbb38d",
            "value": " 781/? [00:06&lt;00:00, 135.23it/s]"
          }
        },
        "e0f314af2d3c40dcb58b7e3ffc92ad7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1783a2c37e498885289bbece8e1b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5cdf616c09642e787ecf1913da28269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "687aad7ea841415da1053adb80c40b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "018666e97f244a23917460bd47df124e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68c3360ba7724ccface54b3535ac7fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3892b85f37164ed28bca0eba8cdbb38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics boxmot fvcore ffmpeg-python opencv-python-headless dash Pillow plotly parse"
      ],
      "metadata": {
        "id": "XMeX5ZH1JY94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91a86e0-d23c-492b-f137-d6c2ed07bc89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.2/282.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FMjRLBxKHoQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a0f7ec-946e-427a-e436-2d58fdde8482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os, csv, json, cv2, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional, Any, DefaultDict, Sequence\n",
        "from collections import defaultdict\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "from IPython.display import Video\n",
        "\n",
        "import ffmpeg\n",
        "from ultralytics import YOLO\n",
        "from boxmot import StrongSort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvag1O1gHtei",
        "outputId": "4190cb32-40f4-4437-efdc-eebcfc56090a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def seed_all(seed=1023):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_all(2310)"
      ],
      "metadata": {
        "id": "IBPmaRCTxDCC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PATHS**"
      ],
      "metadata": {
        "id": "RrTnAUN6A3Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rally = \"asy_wzy_rally_1\"\n",
        "rally = \"shi_vit_rally_1\"\n",
        "# rally = \"syq_anton_rally_1\"\n",
        "\n",
        "INPUT_VIDEO_PATH = f\"/content/{rally}.mp4\"\n",
        "\n",
        "PLAYER_TRACKS_CSV_PATH = f\"/content/{rally}_tracks.csv\"\n",
        "\n",
        "SHUTTLE_CSV_PATH = f\"/content/{rally}_ball.csv\"\n",
        "\n",
        "YOLO_MODEL_PATH = \"/content/drive/MyDrive/FIT3163,3164/YOLO/my_yolo11s_finals.pt\"\n",
        "\n",
        "REID_MODEL_PATH = \"/content/drive/MyDrive/FIT3163,3164/REID/osnet_x1_0_badminton.pt\"\n",
        "\n",
        "SLOWFAST_PATH = \"/content/drive/MyDrive/FIT3163,3164/SlowFast/07_models/slowfast_finals_1b.pt\""
      ],
      "metadata": {
        "id": "ErtuWgq8A4gS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: STRONGSORT**"
      ],
      "metadata": {
        "id": "brwWaneXJvzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class YoloCfg:\n",
        "    conf: float = 0.35\n",
        "    iou: float = 0.5                      # intersection over union threshold: the I:U ratio that is considered as correct\n",
        "    imgsz: int = 1280\n",
        "    max_det: int = 300\n",
        "    classes: Optional[Sequence[int]] = None   # e.g. [0] for COCO 'person'\n",
        "    agnostic_nms: bool = False\n",
        "    verbose: bool = False\n",
        "\n",
        "@dataclass\n",
        "class StrongSortCfg:\n",
        "    # Only applied if attributes exist on your StrongSort build (safe setattr).\n",
        "    max_age: Optional[int] = 40           # keep ID alive across occlusion\n",
        "    n_init: Optional[int] = 3             # frames before confirming a track\n",
        "    max_iou_dist: Optional[float] = 0.7   # motion/overlap gating\n",
        "    max_dist: Optional[float] = 0.2       # appearance/cosine distance gating\n",
        "    nn_budget: Optional[int] = 100        # feature queue size\n",
        "    half: bool = True                     # use FP16 on GPU if available\n",
        "    det_thresh: float = 0.3"
      ],
      "metadata": {
        "id": "H6iMpAJ9JveV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_models(yolo_weights: str, reid_weights: str, ssort_cfg: StrongSortCfg):\n",
        "    device = 0 if torch.cuda.is_available() else 'cpu'\n",
        "    tracker = StrongSort(\n",
        "        reid_weights=Path(reid_weights),\n",
        "        device=device,\n",
        "        half=(ssort_cfg.half and torch.cuda.is_available()),\n",
        "        # BaseTracker parameters\n",
        "        det_thresh=ssort_cfg.det_thresh,\n",
        "        max_age=ssort_cfg.max_age,\n",
        "        n_init=ssort_cfg.n_init,\n",
        "        max_iou_dist=ssort_cfg.max_iou_dist,\n",
        "        max_cos_dist=ssort_cfg.max_dist,\n",
        "        nn_budget=ssort_cfg.nn_budget\n",
        "    )\n",
        "    print(f\"StrongSort args: {vars(tracker)}\")\n",
        "    print(f\"StrongSort Tracker args: {vars(tracker.tracker)}\")\n",
        "\n",
        "    yolo = YOLO(yolo_weights)\n",
        "    return yolo, tracker\n",
        "\n",
        "def yolo_detect(yolo: YOLO, frame: np.ndarray, cfg: YoloCfg):\n",
        "    r = yolo.predict(\n",
        "        frame,\n",
        "        conf=cfg.conf,\n",
        "        iou=cfg.iou,\n",
        "        imgsz=cfg.imgsz,\n",
        "        max_det=cfg.max_det,\n",
        "        classes=cfg.classes,\n",
        "        agnostic_nms=cfg.agnostic_nms,\n",
        "        verbose=cfg.verbose\n",
        "    )[0]\n",
        "    if r.boxes is None or r.boxes.xyxy.numel() == 0:\n",
        "        return None\n",
        "    boxes = r.boxes.xyxy.detach().cpu().numpy()  # [N,4]\n",
        "    confs = r.boxes.conf.detach().cpu().numpy()  # [N]\n",
        "    clss  = r.boxes.cls.detach().cpu().numpy()   # [N]\n",
        "    dets  = np.concatenate([boxes, confs[:, None], clss[:, None]], axis=1)\n",
        "    return dets  # [x1,y1,x2,y2,conf,cls]\n",
        "\n",
        "def draw_tracks(frame: np.ndarray, tracks: np.ndarray, id_color_cache: dict):\n",
        "    # tracks: Nx [x1,y1,x2,y2,track_id,conf,cls,ind]\n",
        "    for tb in tracks:\n",
        "        x1, y1, x2, y2, tid, conf, cls, _ = tb\n",
        "        x1,y1,x2,y2,tid = int(x1),int(y1),int(x2),int(y2),int(tid)\n",
        "        color = id_color_cache.setdefault(tid, (37*tid%256, 17*tid%256, 93*tid%256))\n",
        "        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n",
        "        cv2.putText(frame, f\"ID {tid}\", (x1, max(0, y1-7)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    return frame\n",
        "\n",
        "def export_tracks_csv(csv_path: str, rows: List[Tuple[int,int,int,int,int,int,float,int]]):\n",
        "    # rows: (frame, id, x1,y1,x2,y2, conf, cls)\n",
        "    if not csv_path: return\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"frame\",\"id\",\"x1\",\"y1\",\"x2\",\"y2\",\"conf\",\"cls\"])\n",
        "        w.writerows(rows)"
      ],
      "metadata": {
        "id": "0BHsQNe5J0ge"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def track_video(\n",
        "    src_path: str,\n",
        "    dst_path: str,\n",
        "    yolo: YOLO,\n",
        "    tracker: StrongSort,\n",
        "    yolo_cfg: YoloCfg,\n",
        "    export_csv: Optional[str] = None,\n",
        "    show_pbar: bool = True,\n",
        "):\n",
        "    cap = cv2.VideoCapture(src_path)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open video: {src_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    w, h = int(cap.get(3)), int(cap.get(4))\n",
        "    out = cv2.VideoWriter(dst_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or None\n",
        "    print(f\"🎥 Video Meta: FPS={fps:.2f}, Total Frames={total}\")\n",
        "    pbar = tqdm(total=total, unit=\"frame\", disable=not show_pbar)\n",
        "\n",
        "    csv_rows = []\n",
        "    id_color_cache = {}\n",
        "    frame_idx = 0\n",
        "\n",
        "    t0 = time.time()\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "\n",
        "        dets = yolo_detect(yolo, frame, yolo_cfg)\n",
        "        if dets is None:\n",
        "            out.write(frame)\n",
        "            frame_idx += 1\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        tracks = tracker.update(dets, frame)  # -> Nx [x1,y1,x2,y2,track_id,conf,cls,ind]\n",
        "        if tracks is not None and len(tracks):\n",
        "            # collect CSV rows\n",
        "            for x1,y1,x2,y2,tid,conf,cls,_ in tracks:\n",
        "                csv_rows.append((frame_idx, int(tid), int(x1), int(y1), int(x2), int(y2), float(conf), int(cls)))\n",
        "            # draw\n",
        "            frame = draw_tracks(frame, tracks, id_color_cache)\n",
        "\n",
        "        cv2.putText(\n",
        "            frame, text=f\"Frame {frame_idx}\", org=(50, 200),\n",
        "            fontScale=1.3, color=(0, 0, 255), thickness=4, fontFace=cv2.FONT_HERSHEY_SIMPLEX\n",
        "        )\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "    cap.release(); out.release()\n",
        "    pbar.close()\n",
        "    t1 = time.time()\n",
        "    print(f\"Saved video to: {dst_path} | frames={frame_idx} | time={t1-t0:.1f}s | ~{frame_idx/max(t1-t0,1):.1f} FPS\")\n",
        "    if export_csv:\n",
        "        export_tracks_csv(export_csv, csv_rows)\n",
        "        print(f\"Saved track CSV to: {export_csv}\")"
      ],
      "metadata": {
        "id": "hG2W5uiRJ9zY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Track Shuttle**"
      ],
      "metadata": {
        "id": "dfgii8m5LcBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/qaz812345/TrackNetV3.git\n",
        "\n",
        "# Get model checkpoints\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1CfzE87a0f6LhBp0kniSl1-89zaLCZ8cA/view?usp=sharing\n",
        "!unzip /content/TrackNetV3_ckpts.zip\n",
        "!mv ckpts TrackNetV3/ckpts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXmIf7H7LhfK",
        "outputId": "cce85b0a-ed8c-48e6-d349-6ca0d71d75a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrackNetV3'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 240 (delta 99), reused 87 (delta 87), pack-reused 129 (from 1)\u001b[K\n",
            "Receiving objects: 100% (240/240), 2.82 MiB | 62.67 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1CfzE87a0f6LhBp0kniSl1-89zaLCZ8cA\n",
            "From (redirected): https://drive.google.com/uc?id=1CfzE87a0f6LhBp0kniSl1-89zaLCZ8cA&confirm=t&uuid=59ba954c-0bc6-4883-bb7e-7b916f594273\n",
            "To: /content/TrackNetV3_ckpts.zip\n",
            "100% 132M/132M [00:03<00:00, 36.8MB/s]\n",
            "Archive:  /content/TrackNetV3_ckpts.zip\n",
            "   creating: ckpts/\n",
            "  inflating: ckpts/InpaintNet_best.pt  \n",
            "  inflating: ckpts/TrackNet_best.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Get Contact Points**"
      ],
      "metadata": {
        "id": "tZ49aJ76z2Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ContactConfig:\n",
        "    \"\"\"Configuration for dataset preparation\"\"\"\n",
        "    window_size: int = 21  # frames to look at around each point (odd number). 21 means 10 before and 10 after\n",
        "    temporal_stride: int = 5  # stride for negative sampling (reduce dataset size)\n",
        "    positive_window: int = 5  # frames around true contact to mark as positive\n",
        "\n",
        "    # Feature engineering\n",
        "    compute_velocity: bool = True\n",
        "    compute_acceleration: bool = True\n",
        "    compute_direction: bool = True\n",
        "    smooth_window: int = 5\n",
        "\n",
        "class ContactDetector:\n",
        "    \"\"\"Inference class for detecting contact points from shuttle CSV\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        cfg: ContactConfig,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        self.model = model.to(device)\n",
        "        self.model.eval()\n",
        "        self.device = device\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def predict_csv(\n",
        "        self,\n",
        "        csv_path: str,\n",
        "        confidence_threshold: float = 0.5,\n",
        "        nms_window: int = 10\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predict contact frames from shuttle CSV.\n",
        "\n",
        "        Args:\n",
        "            csv_path: Path to shuttle CSV file\n",
        "            confidence_threshold: Minimum confidence for detection\n",
        "            nms_window: Non-maximum suppression window (frames)\n",
        "\n",
        "        Returns:\n",
        "            List of contact frame numbers\n",
        "        \"\"\"\n",
        "        # Load CSV\n",
        "        frames, vis, xs, ys = self._load_csv(csv_path)\n",
        "\n",
        "        # Extract features\n",
        "        features = self._extract_features(xs, ys, vis)\n",
        "\n",
        "        # Sliding window inference\n",
        "        probabilities = self._sliding_window_inference(features)\n",
        "\n",
        "        # Map probabilities back to frame numbers\n",
        "        half_window = self.cfg.window_size // 2\n",
        "        valid_frames = frames[half_window:-half_window]\n",
        "\n",
        "        # Apply threshold and NMS\n",
        "        contact_frames = self._detect_peaks(\n",
        "            valid_frames, probabilities, confidence_threshold, nms_window\n",
        "        )\n",
        "\n",
        "        return contact_frames\n",
        "\n",
        "    def _load_csv(self, path: str):\n",
        "        \"\"\"Load shuttle CSV (same as dataset)\"\"\"\n",
        "        frames, vis, xs, ys = [], [], [], []\n",
        "        with open(path, 'r') as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for r in reader:\n",
        "                frames.append(int(r[\"Frame\"]))\n",
        "                vis.append(int(r[\"Visibility\"]))\n",
        "                xs.append(float(r[\"X\"]))\n",
        "                ys.append(float(r[\"Y\"]))\n",
        "\n",
        "        frames = np.array(frames)\n",
        "        vis = np.array(vis)\n",
        "        xs = np.array(xs, dtype=np.float32)\n",
        "        ys = np.array(ys, dtype=np.float32)\n",
        "\n",
        "        idx = np.argsort(frames)\n",
        "        return frames[idx], vis[idx], xs[idx], ys[idx]\n",
        "\n",
        "    def _extract_features(self, xs, ys, vis):\n",
        "        \"\"\"Extract features (same as dataset)\"\"\"\n",
        "        # [Same implementation as in ShuttleContactDataset]\n",
        "        xs_filled = xs.copy()\n",
        "        ys_filled = ys.copy()\n",
        "        valid = (vis == 1) & ~((xs == 0) & (ys == 0))\n",
        "\n",
        "        for i in range(1, len(xs)):\n",
        "            if not valid[i]:\n",
        "                xs_filled[i] = xs_filled[i-1]\n",
        "                ys_filled[i] = ys_filled[i-1]\n",
        "\n",
        "        def smooth(arr, window):\n",
        "            if window < 2:\n",
        "                return arr\n",
        "            if window % 2 == 0:\n",
        "                window += 1\n",
        "            pad = window // 2\n",
        "            padded = np.pad(arr, pad, mode='edge')\n",
        "            kernel = np.ones(window) / window\n",
        "            return np.convolve(padded, kernel, mode='valid').astype(np.float32)\n",
        "\n",
        "        xs_s = smooth(xs_filled, self.cfg.smooth_window)\n",
        "        ys_s = smooth(ys_filled, self.cfg.smooth_window)\n",
        "\n",
        "        features = [xs_s, ys_s]\n",
        "\n",
        "        vx = np.diff(xs_s, prepend=xs_s[0])\n",
        "        vy = np.diff(ys_s, prepend=ys_s[0])\n",
        "        speed = np.sqrt(vx**2 + vy**2)\n",
        "        features.extend([vx, vy, speed])\n",
        "\n",
        "        ax = np.diff(vx, prepend=vx[0])\n",
        "        ay = np.diff(vy, prepend=vy[0])\n",
        "        features.extend([ax, ay])\n",
        "\n",
        "        direction = np.arctan2(vy, vx)\n",
        "        direction_change = np.diff(direction, prepend=direction[0])\n",
        "        features.extend([direction, direction_change])\n",
        "\n",
        "        return np.stack(features, axis=1)\n",
        "\n",
        "    def _sliding_window_inference(self, features):\n",
        "        \"\"\"Run model on sliding windows\"\"\"\n",
        "        N = len(features)\n",
        "        half_window = self.cfg.window_size // 2\n",
        "        probabilities = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(half_window, N - half_window):\n",
        "                start_idx = i - half_window\n",
        "                end_idx = i + half_window + 1\n",
        "                window = features[start_idx:end_idx]\n",
        "\n",
        "                # Prepare input\n",
        "                window_tensor = torch.tensor(window, dtype=torch.float32).T.unsqueeze(0)\n",
        "                window_tensor = window_tensor.to(self.device)\n",
        "\n",
        "                # Predict\n",
        "                output = self.model(window_tensor)\n",
        "                prob = F.softmax(output, dim=1)[0, 1].item()  # probability of contact\n",
        "                probabilities.append(prob)\n",
        "\n",
        "        return np.array(probabilities)\n",
        "\n",
        "    def _detect_peaks(self, frames, probabilities, threshold, nms_window):\n",
        "        \"\"\"Detect peaks in probability curve with NMS\"\"\"\n",
        "        # Threshold\n",
        "        candidates = []\n",
        "        for i, prob in enumerate(probabilities):\n",
        "            if prob >= threshold:\n",
        "                candidates.append((frames[i], prob))\n",
        "\n",
        "        if not candidates:\n",
        "            return []\n",
        "\n",
        "        # Sort by probability (descending)\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # NMS: keep peaks that are far enough apart\n",
        "        selected = []\n",
        "        for frame, prob in candidates:\n",
        "            # Check if too close to already selected peaks\n",
        "            too_close = any(abs(frame - sel) < nms_window for sel in selected)\n",
        "            if not too_close:\n",
        "                selected.append(frame)\n",
        "\n",
        "        return sorted(selected)"
      ],
      "metadata": {
        "id": "Pj-v0NNS_VPT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContactDetectionCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    1D CNN for temporal contact detection.\n",
        "\n",
        "    Architecture:\n",
        "    - Multiple Conv1D layers to capture temporal patterns\n",
        "    - Residual connections for gradient flow\n",
        "    - Global pooling to handle variable-length sequences\n",
        "    - Binary classification head\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_features: int, hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv1d(input_features, hidden_dim, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(hidden_dim, hidden_dim * 2, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_dim * 2)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(hidden_dim * 2, hidden_dim * 2, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(hidden_dim * 2)\n",
        "\n",
        "        # Global pooling + classification\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, 2)  # binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, features, time)\n",
        "\n",
        "        # Conv blocks with residuals\n",
        "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        x2 = F.relu(self.bn2(self.conv2(x1)))\n",
        "        x2 = x2 + x1  # residual\n",
        "\n",
        "        x3 = F.relu(self.bn3(self.conv3(x2)))\n",
        "        x4 = F.relu(self.bn4(self.conv4(x3)))\n",
        "        x4 = x4 + x3  # residual\n",
        "\n",
        "        # Global pool and classify\n",
        "        x_pooled = self.pool(x4).squeeze(-1)  # (batch, hidden*2)\n",
        "        logits = self.fc(x_pooled)  # (batch, 2)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "rflt2SD1_kdi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_contact_model_v3.pth\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1OLCLAL6FtZCcHK6tY9wJ1G2o0VtfQSxb/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiuzkcRx_o2O",
        "outputId": "87b24fdf-dde0-42a7-e887-df8b122962b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OLCLAL6FtZCcHK6tY9wJ1G2o0VtfQSxb\n",
            "To: /content/best_contact_model_v3.pth\n",
            "\r  0% 0.00/441k [00:00<?, ?B/s]\r100% 441k/441k [00:00<00:00, 131MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utilities**"
      ],
      "metadata": {
        "id": "UR3mu6RiHw4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _device():\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def _linspace_idx(a: int, b: int, n: int) -> List[int]:\n",
        "    if n <= 1 or b <= a:\n",
        "        return [a] * max(n, 1)\n",
        "    return np.round(np.linspace(a, b, n)).astype(int).tolist()\n",
        "\n",
        "def _expand_to_square(x1, y1, x2, y2, W, H, factor=1.25):\n",
        "    cx, cy = 0.5*(x1+x2), 0.5*(y1+y2)\n",
        "    w, h = (x2-x1), (y2-y1)\n",
        "    s = max(w, h) * factor\n",
        "    nx1 = int(max(0, math.floor(cx - 0.5*s)))\n",
        "    ny1 = int(max(0, math.floor(cy - 0.5*s)))\n",
        "    nx2 = int(min(W-1, math.ceil (cx + 0.5*s)))\n",
        "    ny2 = int(min(H-1, math.ceil (cy + 0.5*s)))\n",
        "    if nx2 <= nx1: nx2 = min(W-1, nx1+1)\n",
        "    if ny2 <= ny1: ny2 = min(H-1, ny1+1)\n",
        "    return nx1, ny1, nx2, ny2\n",
        "\n",
        "def _color_for_id(tid: int):\n",
        "    # stable-ish distinct color per track id\n",
        "    return (37*tid % 256, 17*tid % 256, 93*tid % 256)"
      ],
      "metadata": {
        "id": "G0PI_d6w2XCa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Tracks CSV**"
      ],
      "metadata": {
        "id": "EGMUDq0oH329"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tracks_df(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df[\"frame\"] = df[\"frame\"].astype(int)\n",
        "    df[\"id\"] = df[\"id\"].astype(int)\n",
        "    for c in (\"x1\",\"y1\",\"x2\",\"y2\"):\n",
        "        df[c] = df[c].astype(float)\n",
        "    return df\n",
        "\n",
        "def per_player_lookup(df: pd.DataFrame) -> Dict[int, Dict[int, Tuple[float,float,float,float]]]:\n",
        "    look = {}\n",
        "    for pid in df[\"id\"].unique():\n",
        "        sub = df[df[\"id\"] == pid][[\"frame\",\"x1\",\"y1\",\"x2\",\"y2\"]]\n",
        "        look[int(pid)] = {int(r.frame):(float(r.x1),float(r.y1),float(r.x2),float(r.y2)) for r in sub.itertuples(index=False)}\n",
        "    return look\n",
        "\n",
        "def nearest_bbox(ff: int, lookup: Dict[int, Tuple[float,float,float,float]], span: int=3):\n",
        "    if ff in lookup:\n",
        "        return lookup[ff]\n",
        "    for d in range(1, span+1):\n",
        "        if ff-d in lookup: return lookup[ff-d]\n",
        "        if ff+d in lookup: return lookup[ff+d]\n",
        "    return None\n",
        "\n",
        "def gather_dense_boxes(pid_lookup: Dict[int, Tuple[float,float,float,float]],\n",
        "                       t0: int, t1: int, span: int=3) -> Optional[List[Tuple[int,int,int,int]]]:\n",
        "    boxes = []\n",
        "    for f in range(t0, t1+1):\n",
        "        bb = nearest_bbox(f, pid_lookup, span=span)\n",
        "        if bb is None:\n",
        "            return None\n",
        "        x1,y1,x2,y2 = bb\n",
        "        boxes.append((int(x1),int(y1),int(x2),int(y2)))\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "a7sb1tWy2vkj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Sampling with SlowFast**"
      ],
      "metadata": {
        "id": "T2QFuCm-ILoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SlowFastInferCfg:\n",
        "    slow_t: int = 8\n",
        "    alpha: int = 4\n",
        "    side: int = 224\n",
        "    mean: Tuple[float,float,float] = (0.45, 0.45, 0.45)\n",
        "    std:  Tuple[float,float,float] = (0.225, 0.225, 0.225)\n",
        "    bbox_margin: float = 1.3\n",
        "    bbox_ema: float = 0.8"
      ],
      "metadata": {
        "id": "i37FzVG-INJD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_indices(L: int, slow_t: int, alpha: int):\n",
        "    need_fast = slow_t * alpha\n",
        "    idx_fast = _linspace_idx(0, max(0, L-1), need_fast)\n",
        "    idx_slow = idx_fast[::alpha]\n",
        "    if len(idx_slow) < slow_t:\n",
        "        idx_slow += [idx_slow[-1]] * (slow_t - len(idx_slow))\n",
        "    elif len(idx_slow) > slow_t:\n",
        "        idx_slow = idx_slow[:slow_t]\n",
        "    return idx_slow, idx_fast\n",
        "\n",
        "def extract_clip_slowfast(frames_dict: Dict[int, np.ndarray],\n",
        "                          segment: Tuple[int,int],\n",
        "                          dense_boxes: List[Tuple[int,int,int,int]],\n",
        "                          sfcfg: SlowFastInferCfg):\n",
        "    \"\"\"\n",
        "    frames_dict: {frame_idx -> BGR frame}\n",
        "    segment: inclusive [t0, t1]\n",
        "    dense_boxes: per-frame (x1,y1,x2,y2) aligned to t0..t1 (same length as segment)\n",
        "    \"\"\"\n",
        "    t0, t1 = segment\n",
        "    L = t1 - t0 + 1\n",
        "    if L <= 0 or len(dense_boxes) < L:\n",
        "        return torch.empty(0), torch.empty(0)\n",
        "\n",
        "    # Smooth bbox sequence (EMA)\n",
        "    smoothed = []\n",
        "    prev = None\n",
        "    for b in dense_boxes[:L]:\n",
        "        arr = np.array(b, dtype=np.float32)\n",
        "        prev = arr if prev is None else sfcfg.bbox_ema * prev + (1.0 - sfcfg.bbox_ema) * arr\n",
        "        smoothed.append(tuple(prev.astype(int)))\n",
        "\n",
        "    # Collect crops\n",
        "    # infer frame shape from any available frame\n",
        "    any_im = frames_dict.get(t0, None)\n",
        "    if any_im is None:\n",
        "        return torch.empty(0), torch.empty(0)\n",
        "    H, W = any_im.shape[:2]\n",
        "\n",
        "    crops = []\n",
        "    for k in range(L):\n",
        "        fidx = t0 + k\n",
        "        fr = frames_dict.get(fidx)\n",
        "        if fr is None:\n",
        "            # pad by repeating last valid frame\n",
        "            fr = crops[-1] if len(crops) else any_im\n",
        "\n",
        "        x1,y1,x2,y2 = smoothed[k]\n",
        "        sx1, sy1, sx2, sy2 = _expand_to_square(x1, y1, x2, y2, W, H, factor=sfcfg.bbox_margin)\n",
        "        crop = fr[sy1:sy2, sx1:sx2]\n",
        "        if crop.size == 0:\n",
        "            crop = fr\n",
        "        crop = cv2.resize(crop, (sfcfg.side, sfcfg.side), interpolation=cv2.INTER_AREA)\n",
        "        crops.append(crop)\n",
        "\n",
        "    idx_slow, idx_fast = sample_indices(len(crops), sfcfg.slow_t, sfcfg.alpha)\n",
        "\n",
        "    def _pack(frames_bgr_idx):\n",
        "        if not frames_bgr_idx:\n",
        "            return torch.empty(0)\n",
        "        arr = np.stack([cv2.cvtColor(crops[i], cv2.COLOR_BGR2RGB) for i in frames_bgr_idx]).astype(np.float32)/255.0\n",
        "        arr = (arr - np.array(sfcfg.mean)) / np.array(sfcfg.std)\n",
        "        # (T,H,W,C) -> (C,T,H,W)\n",
        "        return torch.from_numpy(np.transpose(arr, (3,0,1,2))).float()\n",
        "\n",
        "    slow = _pack(idx_slow)\n",
        "    fast = _pack(idx_fast)\n",
        "    return slow, fast"
      ],
      "metadata": {
        "id": "QghuH26a2azK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load SlowFast**"
      ],
      "metadata": {
        "id": "TuhMYqWEITaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SlowFastPredictor:\n",
        "    def __init__(self, model, device=None):\n",
        "        self.model = model.eval()\n",
        "        self.device = device or _device()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_batch(self, slow_list: List[torch.Tensor], fast_list: List[torch.Tensor]) -> np.ndarray:\n",
        "        if not slow_list:\n",
        "            return np.empty((0,0))\n",
        "        slow = torch.stack(slow_list).to(self.device)\n",
        "        fast = torch.stack(fast_list).to(self.device)\n",
        "        logits = self.model([slow, fast])\n",
        "        return torch.softmax(logits, dim=1).cpu().numpy()"
      ],
      "metadata": {
        "id": "ycyF5g98IUmK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_slowfast_classifier(cfg, ckpt_path: str, device: Optional[torch.device] = None):\n",
        "    device = device or _device()\n",
        "    print(f\"🧠 Loading SlowFast model from: {ckpt_path}\")\n",
        "    torch.hub._validate_not_a_forked_repo = lambda a,b,c: True\n",
        "    model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r101', pretrained=True)\n",
        "    in_dim = model.blocks[-1].proj.in_features\n",
        "    model.blocks[-1].proj = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(in_dim, 128),\n",
        "        nn.Dropout(p=0.3), # Add a dropout layer\n",
        "        nn.Linear(128, len(cfg.labels))\n",
        "    )\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "    model.eval().to(device)\n",
        "    print(f\"   -> Model loaded on {device}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "7TPDaSYtIWfL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main function**"
      ],
      "metadata": {
        "id": "MDDVvSCnIW9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class InferenceCfg:\n",
        "    labels: List[str]\n",
        "    sf: SlowFastInferCfg\n",
        "    n_before_after: int = 10      # window size: [c-n, c+n]\n",
        "    search_span: int = 3          # bbox nearest fill +/- frames"
      ],
      "metadata": {
        "id": "EnNTtkUz3EXO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainCfg:\n",
        "    labels = [\n",
        "        \"block\", \"clear\", \"cross_net\",\n",
        "        \"drive\", \"drop\", \"jump_smash\",\n",
        "        \"lift\", \"push\", \"serve\",\n",
        "        \"smash\", \"straight_net\", \"tap\",\n",
        "        \"negative\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "x7_wKXkq4mTM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_video_to_events(\n",
        "        video_path: str,\n",
        "        tracks_csv: str,\n",
        "        contact_frames: List[int],\n",
        "        model,\n",
        "        cfg: InferenceCfg\n",
        "    ) -> Dict:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      {\n",
        "        \"events\": [\n",
        "            {\"track_id\": int, \"t0\": int, \"t1\": int, \"label\": str, \"p\": float},\n",
        "            ...\n",
        "        ],\n",
        "        \"contacts\": contact_frames\n",
        "      }\n",
        "    \"\"\"\n",
        "    # 1) Read tracks and build lookups\n",
        "    df = load_tracks_df(tracks_csv)\n",
        "    print(f\"Loaded player tracks CSV.\")\n",
        "    by_pid = per_player_lookup(df)\n",
        "    player_ids = sorted(by_pid.keys())\n",
        "\n",
        "    # 2) Open video and cache any frames we touch\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"Total frames in video: {total_frames}.\")\n",
        "\n",
        "    frame_cache: Dict[int, np.ndarray] = {}\n",
        "    def get_frame(fidx: int) -> Optional[np.ndarray]:\n",
        "        if fidx in frame_cache:\n",
        "            return frame_cache[fidx]\n",
        "        if fidx < 0 or fidx >= total_frames:\n",
        "            return None\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, fidx)\n",
        "        ok, fr = cap.read()\n",
        "        if not ok:\n",
        "            return None\n",
        "        frame_cache[fidx] = fr\n",
        "        return fr\n",
        "\n",
        "    # 3) For efficiency, prefetch all frames needed by all contacts\n",
        "    needed = set()\n",
        "    for c in contact_frames:\n",
        "        t0 = max(0, c - cfg.n_before_after)\n",
        "        t1 = min(total_frames - 1, c + cfg.n_before_after)\n",
        "        needed.update(range(t0, t1+1))\n",
        "    for fidx in tqdm(sorted(needed), desc=\"Pre-fetching frames: \"):\n",
        "        _ = get_frame(fidx)\n",
        "\n",
        "    # 4) Build batches & run model\n",
        "    predictor = SlowFastPredictor(model, device=_device())\n",
        "    slow_batch, fast_batch, metas = [], [], []\n",
        "\n",
        "    for c in tqdm(contact_frames, desc=\"Processing contact frames: \"):\n",
        "        t0 = c - cfg.n_before_after\n",
        "        t1 = c + cfg.n_before_after\n",
        "        if t0 < 0 or t1 >= total_frames:\n",
        "            # skip if outside bounds\n",
        "            continue\n",
        "\n",
        "        # Create frames_dict for this window\n",
        "        frames_dict = {f: frame_cache.get(f) for f in range(t0, t1+1)}\n",
        "        # For each player present in tracks\n",
        "        for pid in player_ids:\n",
        "            # Gather dense bboxes for this pid across window\n",
        "            dense = gather_dense_boxes(by_pid[pid], t0, t1, span=cfg.search_span)\n",
        "            if dense is None:\n",
        "                continue\n",
        "\n",
        "            slow_t, fast_t = extract_clip_slowfast(frames_dict, (t0, t1), dense, cfg.sf)\n",
        "            if slow_t.numel() == 0 or fast_t.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            slow_batch.append(slow_t)\n",
        "            fast_batch.append(fast_t)\n",
        "            metas.append((pid, t0, t1))\n",
        "\n",
        "    events = []\n",
        "    if slow_batch:\n",
        "        print(f\"Predicting batch with SlowFast.\")\n",
        "        probs = predictor.predict_batch(slow_batch, fast_batch)\n",
        "        for (pid, t0, t1), p in (zip(metas, probs)):\n",
        "            k = int(np.argmax(p))\n",
        "            events.append({\n",
        "                \"track_id\": int(pid),\n",
        "                \"t0\": int(t0),\n",
        "                \"t1\": int(t1),\n",
        "                \"label\": cfg.labels[k],\n",
        "                \"p\": float(p[k]),\n",
        "            })\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Completed.\")\n",
        "    events.sort(key=lambda e: (e[\"t0\"], e[\"track_id\"]))\n",
        "    return {\"events\": events, \"contacts\": [int(c) for c in contact_frames]}"
      ],
      "metadata": {
        "id": "rqU6HhfHIafg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Overlay on video**"
      ],
      "metadata": {
        "id": "3ZQUWXrkTzL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_events_and_contacts(events_json_path: str):\n",
        "    \"\"\"Loads an events JSON file.\"\"\"\n",
        "    with open(events_json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return data.get(\"events\", data), data.get(\"contacts\", data)\n",
        "\n",
        "def build_event_map_by_frame(events: List[Dict]) -> Dict[int, Dict[int, Dict]]:\n",
        "    \"\"\"Converts a list of events into a per-frame lookup: {frame: {track_id: event}}.\"\"\"\n",
        "    by_frame: DefaultDict[int, Dict[int, Dict]] = defaultdict(dict)\n",
        "    for e in events:\n",
        "        for fr in range(int(e[\"t0\"]), int(e[\"t1\"]) + 1):\n",
        "            by_frame[fr][int(e[\"track_id\"])] = e\n",
        "    return by_frame\n",
        "\n",
        "def load_tracks_csv_overlay(csv_path: str):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      boxes_by_frame: {frame_idx: [(tid, (x1,y1,x2,y2)) ...]}\n",
        "    \"\"\"\n",
        "    boxes_by_frame = defaultdict(list)\n",
        "    with open(csv_path, \"r\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            fi = int(row[\"frame\"])\n",
        "            tid = int(row[\"id\"])\n",
        "            x1,y1,x2,y2 = int(row[\"x1\"]), int(row[\"y1\"]), int(row[\"x2\"]), int(row[\"y2\"])\n",
        "            boxes_by_frame[fi].append((tid, (x1,y1,x2,y2)))\n",
        "    return boxes_by_frame"
      ],
      "metadata": {
        "id": "qZX0KfTgJSdx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_full_video_overlay(\n",
        "    video_frames: List[np.ndarray], # MODIFIED: Accepts frames list\n",
        "    tracks_csv: str,\n",
        "    shuttle_csv: str,\n",
        "    events_json: str,\n",
        "    out_path: str,\n",
        "    fps: float,                     # ADDED: Accepts fps\n",
        "    show_ids: bool = True,\n",
        "    label_bg_alpha: float = 0.4\n",
        "):\n",
        "    boxes_by_frame = defaultdict(list)\n",
        "    with open(tracks_csv, \"r\") as f:\n",
        "        for r in csv.DictReader(f):\n",
        "            boxes_by_frame[int(r[\"frame\"])].append((int(r[\"id\"]), (int(r[\"x1\"]), int(r[\"y1\"]), int(r[\"x2\"]), int(r[\"y2\"]))))\n",
        "\n",
        "    shuttle_coordinates = defaultdict(list)\n",
        "    with open(shuttle_csv, \"r\") as f2:\n",
        "        for r in csv.DictReader(f2):\n",
        "            shuttle_coordinates[int(r[\"Frame\"])].extend([int(r[\"X\"]), int(r[\"Y\"])])\n",
        "\n",
        "    events, contacts = load_events_and_contacts(events_json)\n",
        "    event_by_frame = build_event_map_by_frame(events)\n",
        "\n",
        "    # Get video dimensions from the first frame\n",
        "    if not video_frames:\n",
        "        print(\"Warning: video_frames list is empty. Cannot generate overlay.\")\n",
        "        return\n",
        "    H, W, _ = video_frames[0].shape\n",
        "\n",
        "    scale = max(H, W) / 1080.0\n",
        "\n",
        "    BOX_TH       = max(3, int(round(6 * scale)))           # colored box thickness\n",
        "    OUTLINE_TH   = BOX_TH + max(2, int(round(2 * scale)))  # black outline thickness\n",
        "    FONT_SCALE   = max(0.8, 0.9 * scale)                   # text size\n",
        "    TXT_TH       = max(2, int(round(3 * scale)))           # text thickness (white fill)\n",
        "    STROKE_TH    = TXT_TH + max(1, int(round(2 * scale)))  # black text stroke\n",
        "    PAD          = max(6, int(round(8 * scale)))           # label padding\n",
        "    BG_ALPHA     = max(label_bg_alpha, 0.65)               # stronger translucent label bg\n",
        "\n",
        "    # --- FFMPEG LOGIC ---\n",
        "    # MODIFIED: Uses the passed 'fps' parameter\n",
        "    process = (\n",
        "        ffmpeg\n",
        "        .input('pipe:', format='rawvideo', pix_fmt='bgr24', s=f'{W}x{H}', r=fps)\n",
        "        .output(\n",
        "            out_path,\n",
        "            vcodec='libx264',\n",
        "            pix_fmt='yuv420p',\n",
        "            acodec='aac',\n",
        "            strict='experimental'\n",
        "        )\n",
        "        .overwrite_output()\n",
        "        .run_async(pipe_stdin=True)\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # MODIFIED: Loop over the in-memory frames list\n",
        "        for i, frame in tqdm(enumerate(video_frames), desc=\"Writing video: \"):\n",
        "            overlay_frame = frame.copy()\n",
        "\n",
        "            # Draw shuttlecock\n",
        "            shuttle_color = _color_for_id(5)\n",
        "            cv2.circle(overlay_frame, center=(shuttle_coordinates[i][0], shuttle_coordinates[i][1]),\n",
        "                       radius=10, thickness=5, color=shuttle_color)\n",
        "\n",
        "            # Draw frame number\n",
        "            cv2.putText(overlay_frame, text=f\"Frame {i}\", org=(50, 200),\n",
        "                        fontScale=FONT_SCALE, color=(255, 255, 200), thickness=4, fontFace=cv2.FONT_HERSHEY_SIMPLEX)\n",
        "\n",
        "            # Draw note for contact frames\n",
        "            if i in contacts:\n",
        "                cv2.putText(overlay_frame, text=\"Contact\", org=(50, 250),\n",
        "                            fontScale=FONT_SCALE*1.2, color=(0, 0, 255), thickness=4, fontFace=cv2.FONT_HERSHEY_SIMPLEX)\n",
        "\n",
        "            # Draw bounding boxes\n",
        "            for tid, (x1,y1,x2,y2) in boxes_by_frame.get(i, []):\n",
        "                color = _color_for_id(tid)\n",
        "\n",
        "                # ---- BOLDER BOX: black outline + colored inner, AA lines ----\n",
        "                cv2.rectangle(overlay_frame, (x1, y1), (x2, y2), (0, 0, 0), OUTLINE_TH, lineType=cv2.LINE_AA)\n",
        "                cv2.rectangle(overlay_frame, (x1, y1), (x2, y2), color, BOX_TH, lineType=cv2.LINE_AA)\n",
        "\n",
        "                # ---- LABEL / ID ----\n",
        "                ev = event_by_frame.get(i, {}).get(tid)\n",
        "\n",
        "                # Only draw text if shot is predicted AND is not negative\n",
        "                if ev and ev['label'] != \"negative\":\n",
        "                    text = f\"{ev['label']} {ev['p']:.2f}\"\n",
        "                elif show_ids:\n",
        "                    text = f\"ID {tid}\"\n",
        "                else:\n",
        "                    text = None\n",
        "\n",
        "                if text:\n",
        "                    # Size text\n",
        "                    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, TXT_TH)\n",
        "\n",
        "                    # Place label above box if possible, else below\n",
        "                    tx = x1 + BOX_TH\n",
        "                    ty = y1 - PAD\n",
        "                    if ty - th - PAD < 0:\n",
        "                        ty = y1 + th + PAD\n",
        "\n",
        "                    # Semi-transparent color pill behind text\n",
        "                    bg = overlay_frame.copy()\n",
        "                    cv2.rectangle(\n",
        "                        bg,\n",
        "                        (tx - PAD,          ty - th - int(1.2 * PAD)),\n",
        "                        (tx + tw + PAD,     ty + int(0.6 * PAD)),\n",
        "                        color,\n",
        "                        -1\n",
        "                    )\n",
        "                    overlay_frame = cv2.addWeighted(bg, BG_ALPHA, overlay_frame, 1 - BG_ALPHA, 0)\n",
        "\n",
        "                    # High-contrast text: black stroke + white fill\n",
        "                    cv2.putText(overlay_frame, text, (tx, ty),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (0, 0, 0),\n",
        "                                STROKE_TH, lineType=cv2.LINE_AA)\n",
        "\n",
        "                    cv2.putText(overlay_frame, text, (tx, ty),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (255, 255, 255),\n",
        "                                TXT_TH, lineType=cv2.LINE_AA)\n",
        "\n",
        "            process.stdin.write(overlay_frame.tobytes())\n",
        "\n",
        "    finally:\n",
        "        if process.stdin:\n",
        "            process.stdin.close()\n",
        "        process.wait()\n",
        "        print(f\"FFmpeg process finished. Video saved to {out_path}\")"
      ],
      "metadata": {
        "id": "Iw2M7jj6T3Xg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RUN FULLLL FLOW**"
      ],
      "metadata": {
        "id": "pWOB5HFi4jzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### these are counted in the initialising stage"
      ],
      "metadata": {
        "id": "oirM5nq-oJr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_model, ssort_tracker = load_models(YOLO_MODEL_PATH, REID_MODEL_PATH, ssort_cfg)"
      ],
      "metadata": {
        "id": "vGEI47zaoI8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contact_model = ContactDetectionCNN(input_features=9, hidden_dim=64)\n",
        "contact_model.load_state_dict(torch.load('best_contact_model_v3.pth'))\n",
        "print(f\"ContactDetectionCNN created with {sum(p.numel() for p in contact_model.parameters()):,} parameters.\")"
      ],
      "metadata": {
        "id": "cMB3Ju-7oTth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = _device()\n",
        "slowfast_model = load_slowfast_classifier(cfg=trainconfig, ckpt_path=SLOWFAST_PATH, device=device)"
      ],
      "metadata": {
        "id": "F3x7uhBdoYBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(str(INPUT_VIDEO_PATH))\n",
        "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "all_frames = []\n",
        "while True:\n",
        "    ok, frame = cap.read()\n",
        "    if not ok:\n",
        "        break\n",
        "    all_frames.append(frame)"
      ],
      "metadata": {
        "id": "CH-EIMcjokYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### each video being processed should only go through the code below"
      ],
      "metadata": {
        "id": "efDVXBpeoYw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: StrongSort (YOLO + ReID)**"
      ],
      "metadata": {
        "id": "uWwDD1uwKPTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "max_age: The maximum number of consecutive frames a track can exist without being matched to a new detection before it is deleted.\n",
        "n_init: The minimum number of consecutive detections required before a track is considered \"confirmed\" (and ready to be output).\n",
        "max_iou_dist: The maximum Intersection-over-Union (IoU) distance allowed for a match. Higher values allow a detection to be matched to a track even if it overlaps LESS.\n",
        "max_dist: Higher values allow more distant detections (spatially or in appearance feature space) to be matched to a track.\n",
        "nn_budget: The maximum number of appearance features (from the deep neural network) to store for each track.\n",
        "half: probably to use half precision\n",
        "\"\"\"\n",
        "ssort_cfg = StrongSortCfg(\n",
        "    max_age=30,          # keep IDs alive over occlusions/net crossings # default: 50\n",
        "    n_init=12,             # ori: 3\n",
        "    max_iou_dist=1,     # ori: 0.7\n",
        "    max_dist=1,        # ori: 0.25\n",
        "    nn_budget=240,        # ori: 120\n",
        "    det_thresh=0.4,\n",
        "    half=True\n",
        ")\n",
        "\n",
        "yolo_cfg = YoloCfg(\n",
        "    conf=0.50,           # a bit lower to catch partial players, ori: 0.30\n",
        "    iou=0.8,             # ori: 0.55\n",
        "    imgsz=1280,\n",
        "    max_det=2,          # ori: 200\n",
        "    classes=None,        # e.g., [0] if your model uses COCO 'person'\n",
        "    agnostic_nms=False,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "cvtZO8zTKBf-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_VIDEO_PATH = f\"/content/{rally}_tracks.mp4\"\n",
        "CSV_PATH = f\"/content/{rally}_tracks.csv\"\n",
        "\n",
        "track_video(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH, yolo_model, ssort_tracker, yolo_cfg, export_csv=CSV_PATH, show_pbar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "e421951497af4ad68563f5fce002c342",
            "0ba61b9819ff4a59b53c8e5c79805500",
            "59be82313ef0413c99958af64840d162",
            "a71bf54efca14fe6a359ea96a2ef9df1",
            "20e8feaa268a4f348c4f8a7704fc8cb7",
            "2a5eae1a4954417d9c07c28abfb7d607",
            "50694922114e49b5adb5d68c502df692",
            "e727e9b4a1354ca7b9f374912d38d4fc",
            "04c74175973346eaa8494a1dc3519ac3",
            "1b926eaa2e9c41c5a820d9e38b85ea74",
            "e90ae29c46424a1ba64945c563284fed"
          ]
        },
        "id": "J6dmidOiKfE-",
        "outputId": "98932660-f47a-408f-d870-36f38ee0923e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-11-03 14:59:04.703\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m56\u001b[0m | __init__ - \u001b[1mBaseTracker initialization parameters:\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m57\u001b[0m | __init__ - \u001b[1mdet_thresh: 0.4\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m58\u001b[0m | __init__ - \u001b[1mmax_age: 30\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m59\u001b[0m | __init__ - \u001b[1mmax_obs: 50\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m60\u001b[0m | __init__ - \u001b[1mmin_hits: 3\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m61\u001b[0m | __init__ - \u001b[1miou_threshold: 0.3\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.704\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m62\u001b[0m | __init__ - \u001b[1mper_class: False\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.705\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m63\u001b[0m | __init__ - \u001b[1mnr_classes: 80\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.705\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m64\u001b[0m | __init__ - \u001b[1masso_func: iou\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.705\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/basetracker.py\u001b[0m:\u001b[36m65\u001b[0m | __init__ - \u001b[1mis_obb: False\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:04.739\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/utils/torch_utils.py\u001b[0m:\u001b[36m78\u001b[0m | select_device - \u001b[1mYolo Tracking v15.0.8 🚀 Python-3.12.12 torch-2.8.0+cu126\n",
            "CUDA:0 (NVIDIA L4, 22693MiB)\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:06.382\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/appearance/backends/base_backend.py\u001b[0m:\u001b[36m153\u001b[0m | download_model - \u001b[1m[PID 754] Found existing ReID weights at /content/drive/MyDrive/FIT3163,3164/REID/osnet_x1_0_badminton.pt; skipping download.\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:08.183\u001b[0m | MainProcess/MainThread | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/appearance/reid/registry.py\u001b[0m:\u001b[36m67\u001b[0m | load_pretrained_weights - \u001b[32m\u001b[1mLoaded pretrained weights from /content/drive/MyDrive/FIT3163,3164/REID/osnet_x1_0_badminton.pt\u001b[0m\n",
            "\u001b[32m2025-11-03 14:59:08.377\u001b[0m | MainProcess/MainThread | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m/usr/local/lib/python3.12/dist-packages/boxmot/trackers/strongsort/strongsort.py\u001b[0m:\u001b[36m111\u001b[0m | __init__ - \u001b[32m\u001b[1mInitialized StrongSort\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StrongSort args: {'det_thresh': 0.4, 'max_age': 30, 'max_obs': 50, 'min_hits': 3, 'iou_threshold': 0.3, 'per_class': False, 'nr_classes': 80, 'asso_func_name': 'iou', 'is_obb': False, 'frame_count': 0, 'active_tracks': [], 'per_class_active_tracks': None, '_first_frame_processed': False, '_first_dets_processed': False, 'last_emb_size': None, 'min_conf': 0.1, 'model': <boxmot.appearance.backends.pytorch_backend.PyTorchBackend object at 0x79949241e000>, 'tracker': <boxmot.trackers.strongsort.sort.tracker.Tracker object at 0x7994937ef770>, 'cmc': <boxmot.motion.cmc.ecc.ECC object at 0x79949c187e00>}\n",
            "StrongSort Tracker args: {'metric': <boxmot.trackers.strongsort.sort.linear_assignment.NearestNeighborDistanceMetric object at 0x7994934dc1a0>, 'max_iou_dist': 1, 'max_age': 30, 'n_init': 12, '_lambda': 0, 'ema_alpha': 0.9, 'mc_lambda': 0.98, 'tracks': [], '_next_id': 1, 'cmc': <boxmot.motion.cmc.ecc.ECC object at 0x7994934223c0>}\n",
            "🎥 Video Meta: FPS=30.00, Total Frames=781\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/781 [00:00<?, ?frame/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e421951497af4ad68563f5fce002c342"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video to: /content/shi_vit_rally_1_tracks.mp4 | frames=781 | time=59.4s | ~13.1 FPS\n",
            "Saved track CSV to: /content/shi_vit_rally_1_tracks.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Track Shuttle**"
      ],
      "metadata": {
        "id": "Uu8h7RFnNIA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python TrackNetV3/predict.py --video_file $INPUT_VIDEO_PATH --tracknet_file TrackNetV3/ckpts/TrackNet_best.pt --inpaintnet_file TrackNetV3/ckpts/InpaintNet_best.pt --save_dir ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUSuE2IUNLKX",
        "outputId": "fd967af9-8bc3-44c6-ca2a-88c7a15d114b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100% 49/49 [00:51<00:00,  1.05s/it]\n",
            "100% 48/48 [00:00<00:00, 56.68it/s]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Get Contact Frames**"
      ],
      "metadata": {
        "id": "b-jE9eJpKfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contactconfig = ContactConfig(\n",
        "    window_size=21,\n",
        "    temporal_stride=5,\n",
        "    positive_window=4  # 4 frames before and 4 frames after will be marked as positive\n",
        ")\n",
        "\n",
        "contact_detector = ContactDetector(contact_model, contactconfig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKM7CChKyYX",
        "outputId": "33ae3338-3356-43a7-8a07-f427acf150b1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContactDetectionCNN created with 106,626 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contact_frames = contact_detector.predict_csv(\n",
        "    SHUTTLE_CSV_PATH,\n",
        "    confidence_threshold=0.6,\n",
        "    nms_window=10\n",
        ")\n",
        "\n",
        "CONTACT_FRAMES = [int(frame) for frame in contact_frames]\n",
        "print(f\"Detected {len(CONTACT_FRAMES)} contact frames: {CONTACT_FRAMES}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgA26Rz-IzQe",
        "outputId": "cc4ed789-3174-4cfe-cf6e-31f7b695ebbd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 26 contact frames: [90, 114, 138, 158, 195, 209, 229, 261, 277, 306, 329, 354, 383, 409, 446, 461, 485, 512, 526, 553, 582, 604, 666, 687, 727, 758]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Extract Clips and Run SlowFast Inference**"
      ],
      "metadata": {
        "id": "EnILUPFlKzOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainconfig = TrainCfg()\n",
        "\n",
        "slowfastinferconfig = SlowFastInferCfg(\n",
        "    side=224,\n",
        "    bbox_margin=1.3,\n",
        "    bbox_ema=0.8\n",
        ")\n",
        "\n",
        "inferenceconfig = InferenceCfg(\n",
        "    labels=trainconfig.labels,\n",
        "    sf=slowfastinferconfig,\n",
        "    n_before_after=15,\n",
        "    search_span=3\n",
        ")"
      ],
      "metadata": {
        "id": "oqqZIA0AJIZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e4e3bc-af61-4a64-c561-691827d1fa71"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Loading SlowFast model from: /content/drive/MyDrive/FIT3163,3164/SlowFast/07_models/slowfast_finals_1b.pt\n",
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOWFAST_8x8_R101.pyth\" to /root/.cache/torch/hub/checkpoints/SLOWFAST_8x8_R101.pyth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480M/480M [00:27<00:00, 18.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   -> Model loaded on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_full_video_to_events(\n",
        "    video_path=INPUT_VIDEO_PATH,\n",
        "    tracks_csv=PLAYER_TRACKS_CSV_PATH,\n",
        "    contact_frames=CONTACT_FRAMES,\n",
        "    model=slowfast_model,\n",
        "    cfg=inferenceconfig\n",
        ")\n",
        "\n",
        "with open(f\"{Path(INPUT_VIDEO_PATH).stem}.json\", \"w\") as f:\n",
        "    json.dump(result, f, indent=2)\n",
        "print(f\"Predicted {len(result['events'])} action events\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "d4802404be664e7ca30435b36fc874a2",
            "39f89962b3a44358aea345a98d8bd3c0",
            "da43458b0e0f4a23ae96d375004d0437",
            "e3dda69b7615416ea0b01292e6a52862",
            "e3c11bc10e7e4349b3ac724ded426953",
            "a3050f66ac034ca1a4189eb14e3cbf6a",
            "2d03d715b7b4403bba0f14f3eacadd5e",
            "c5a38122064e479097ad0c47e0132d39",
            "6549bc47949445dfa7b5623e1eaf0909",
            "dca2063eadf14776b50e15c8c9e1a6b4",
            "4f1f1b7315a240c4b39f99e3306c2867",
            "20bd0b26c41848be87edcc1e7fbeacc1",
            "06fb82a5d714432d81d15a02e138c4c9",
            "ae7d3e5efb9c467389e5c70bbfe27ffe",
            "16532d8a911b41198ed017f94f422aca",
            "a867fae6401045558b661aaaf37b705d",
            "64fdbd30b76046558b076576c3f92bfa",
            "acd20d97df7144ca9f81fd55a0c9678f",
            "bd30ccf762ac405287c26e96b4f10d10",
            "9056b47d54e94ccc86b083df27a2f2c6",
            "1192c2b0323a444bac80cf6f7c863db2",
            "6d7d45c2486c42b8a44047c79c514cca"
          ]
        },
        "id": "tVj_Qj34IeDz",
        "outputId": "d887f87b-8759-43ad-ac0c-0da2ecba3bde"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded player tracks CSV.\n",
            "Total frames in video: 781.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Pre-fetching frames:   0%|          | 0/646 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4802404be664e7ca30435b36fc874a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing contact frames:   0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20bd0b26c41848be87edcc1e7fbeacc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting batch with SlowFast.\n",
            "Completed.\n",
            "Predicted 52 action events\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Overlay to Video**"
      ],
      "metadata": {
        "id": "QC9hcEx9K_vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVENTS_JSON = f'{Path(INPUT_VIDEO_PATH).stem}.json'\n",
        "\n",
        "render_full_video_overlay(\n",
        "    video_frames=all_frames,\n",
        "    tracks_csv=PLAYER_TRACKS_CSV_PATH,\n",
        "    shuttle_csv=SHUTTLE_CSV_PATH,\n",
        "    events_json=EVENTS_JSON,\n",
        "    out_path=f\"/content/{Path(INPUT_VIDEO_PATH).stem}_overlay.mp4\",\n",
        "    fps=video_fps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1f613b2a8e9b45989019d17cef448530",
            "42ef43bbe9fc4ad0917e63f984b99c7a",
            "c11fdcdadee14e6aa7878b10eccf520d",
            "88bd04e814904fee8e6e8d3809d5d356",
            "e0f314af2d3c40dcb58b7e3ffc92ad7f",
            "de1783a2c37e498885289bbece8e1b58",
            "f5cdf616c09642e787ecf1913da28269",
            "687aad7ea841415da1053adb80c40b06",
            "018666e97f244a23917460bd47df124e",
            "68c3360ba7724ccface54b3535ac7fc1",
            "3892b85f37164ed28bca0eba8cdbb38d"
          ]
        },
        "id": "yeOdHWq1T5h9",
        "outputId": "4419109b-a517-4f43-ae03-8965deb4c97d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing video: : 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f613b2a8e9b45989019d17cef448530"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FFmpeg process finished. Video saved to /content/shi_vit_rally_1_overlay.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhCzZ8usVoFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}