{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Convert CVAT tracks â†’ canonical shots.csv**\n",
        "\n",
        "- Parse the JSON and create a table with one row per shot track, plus a per-frame bbox series (serialized) so we can crop dynamically.\n",
        "- Schema (04_shots/shots.csv):\n",
        "\n",
        "```\n",
        "video_rel, start_f, end_f, contact_f, shot_type, player_side, src, fps_proxy, bboxes_json\n",
        "\n",
        "# video_rel: e.g., channel/yt_id/proxy.mp4 to map back to master.\n",
        "# bboxes_json: JSON list of [frame_idx, x1, y1, x2, y2] (proxy coordinates).\n",
        "```"
      ],
      "metadata": {
        "id": "sk-am0rbtFkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, csv, os, glob, re\n",
        "from collections import defaultdict\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "-ziMQw9hQwQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jFlWfIQXhSqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057360bb-ec44-40b3-f994-50dc1ef90f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_video_rel(task_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Infers the relative video path from a CVAT task name.\n",
        "\n",
        "    Args:\n",
        "        task_name (str): The name of the CVAT task, e.g., 'channel__ytid__chunkNN'.\n",
        "\n",
        "    Returns:\n",
        "        str: The inferred relative video path, e.g., 'channel/ytid/proxy.mp4'.\n",
        "    \"\"\"\n",
        "    m = re.match(r'([^_]+)__([^_]+)', task_name)\n",
        "    if m:\n",
        "        return f\"{m.group(1)}/{m.group(2)}/proxy.mp4\"\n",
        "    return task_name"
      ],
      "metadata": {
        "id": "hJM59F10TMIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_cvat_json(json_path: str) -> list:\n",
        "    \"\"\"\n",
        "    Processes a single CVAT JSON file (frame-based format) to extract shot track data.\n",
        "\n",
        "    This function handles the new frame-based JSON format:\n",
        "    - It groups annotations by 'track_id' to reconstruct each track.\n",
        "    - It handles the different bounding box format [x, y, w, h].\n",
        "    - It extracts track and frame attributes.\n",
        "    - It returns a list of rows for the CSV.\n",
        "\n",
        "    Args:\n",
        "        json_path (str): The full path to the CVAT JSON file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list represents a row of data\n",
        "              for the output CSV file.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "        print(f\"Error processing {json_path}: {e}\")\n",
        "        return rows\n",
        "\n",
        "    task_name = os.path.basename(os.path.dirname(json_path))\n",
        "    video_rel = infer_video_rel(task_name)\n",
        "\n",
        "    ### CHANGE HERE IF NEEDED, NOW DEFAULT IS 30\n",
        "    fps_proxy = 30 # by construction\n",
        "\n",
        "    # Find the label_id corresponding to \"shot_track\"\n",
        "    shot_track_label_id = None\n",
        "    labels = data.get(\"categories\", {}).get(\"label\", {}).get(\"labels\", [])\n",
        "    for i, label in enumerate(labels):\n",
        "        if label.get(\"name\") == \"shot_track\":\n",
        "            shot_track_label_id = i\n",
        "            break\n",
        "\n",
        "    if shot_track_label_id is None:\n",
        "        print(f\"Warning: No 'shot_track' label found in {json_path}. Skipping.\")\n",
        "        return rows\n",
        "\n",
        "    # Group annotations by track_id\n",
        "    tracks_data = defaultdict(list)\n",
        "    # The new format stores annotations per frame in the `items` list\n",
        "    for item in data.get(\"items\", []):\n",
        "        frame_num = item.get(\"attr\", {}).get(\"frame\")\n",
        "        if frame_num is None:\n",
        "            continue\n",
        "\n",
        "        for annotation in item.get(\"annotations\", []):\n",
        "            # Check for the correct label_id and type\n",
        "            if annotation.get(\"type\") == \"bbox\" and annotation.get(\"label_id\") == shot_track_label_id:\n",
        "                track_id = annotation.get(\"attributes\", {}).get(\"track_id\")\n",
        "                if track_id is not None:\n",
        "                    # Append a tuple of (frame, annotation) to the corresponding track\n",
        "                    tracks_data[track_id].append((frame_num, annotation))\n",
        "\n",
        "    # Process each reconstructed track\n",
        "    for track_id, annotations_list in tracks_data.items():\n",
        "        if not annotations_list:\n",
        "            continue\n",
        "\n",
        "        # Extract track-level attributes and frames from the first annotation in the track\n",
        "        # Assuming track-level attributes are consistent across all frames for a track\n",
        "        track_attrs = annotations_list[0][1].get(\"attributes\", {})\n",
        "        shot_type = track_attrs.get(\"shot_type\", \"other\").strip('\"')\n",
        "        player_side = track_attrs.get(\"player_side\", \"unknown\").strip('\"')\n",
        "\n",
        "        frames = sorted([f for f, _ in annotations_list])\n",
        "        start_f, end_f = min(frames), max(frames)\n",
        "\n",
        "        # Look for the contact frame\n",
        "        contact_f = None\n",
        "        for frame_num, annotation in annotations_list:\n",
        "            attrs = annotation.get(\"attributes\", {})\n",
        "            # Check for both \"is_contact\" and \"contact_frame\" attributes\n",
        "            if \"is_contact\" in attrs and (str(attrs[\"is_contact\"]).lower() in [\"true\", \"1\", \"yes\"]):\n",
        "                contact_f = frame_num\n",
        "                break\n",
        "            if \"contact_frame\" in attrs and str(attrs[\"contact_frame\"]).strip().isdigit():\n",
        "                contact_f = int(attrs[\"contact_frame\"])\n",
        "                break\n",
        "\n",
        "        # Serialize bounding boxes\n",
        "        bboxes = []\n",
        "        for frame_num, annotation in annotations_list:\n",
        "            # New format: [x, y, width, height]\n",
        "            x, y, w, h = annotation[\"bbox\"]\n",
        "            # Convert to [x1, y1, x2, y2]\n",
        "            x1, y1, x2, y2 = x, y, x + w, y + h\n",
        "            bboxes.append([int(frame_num), float(x1), float(y1), float(x2), float(y2)])\n",
        "\n",
        "        rows.append([\n",
        "            video_rel,\n",
        "            start_f,\n",
        "            end_f,\n",
        "            contact_f,\n",
        "            shot_type,\n",
        "            player_side,\n",
        "            \"youtube\",\n",
        "            fps_proxy,\n",
        "            json.dumps(bboxes)\n",
        "        ])\n",
        "\n",
        "    return rows"
      ],
      "metadata": {
        "id": "t2XiUEDBuVyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_data(rows: list, output_path: str):\n",
        "    \"\"\"\n",
        "    Writes a list of data rows to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        rows (list): A list of lists, where each inner list is a row of data.\n",
        "        output_path (str): The full path to the output CSV file.\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"video_rel\", \"start_f\", \"end_f\", \"contact_f\", \"shot_type\", \"player_side\", \"src\", \"fps_proxy\", \"bboxes_json\"])\n",
        "        w.writerows(rows)\n",
        "    print(f\"Written {len(rows)} rows to {output_path}\")"
      ],
      "metadata": {
        "id": "LiMdASdZuX61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_cvat_files(exports_dir: str, output_csv_path: str):\n",
        "    \"\"\"\n",
        "    Finds and processes all CVAT JSON files in a directory and writes the\n",
        "    combined data to a single CSV.\n",
        "\n",
        "    Args:\n",
        "        exports_dir (str): The directory containing the CVAT exports.\n",
        "        output_csv_path (str): The full path for the output CSV file.\n",
        "    \"\"\"\n",
        "    all_rows = []\n",
        "    # Use glob to find all cvat.json files\n",
        "    json_files = glob.glob(os.path.join(exports_dir, \"*\", \"cvat.json\"))\n",
        "\n",
        "    if not json_files:\n",
        "        print(f\"No CVAT JSON files found in '{exports_dir}'.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(json_files)} files to process.\")\n",
        "    for json_path in json_files:\n",
        "        rows_from_file = process_cvat_json(json_path)\n",
        "        all_rows.extend(rows_from_file)\n",
        "\n",
        "    write_csv_data(all_rows, output_csv_path)"
      ],
      "metadata": {
        "id": "9wLrAO1HuYfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_specific_cvat_files(json_paths: List[str], output_csv_path: str):\n",
        "    \"\"\"\n",
        "    Processes a list of specific CVAT JSON files and combines the\n",
        "    data into a single CSV.\n",
        "\n",
        "    Args:\n",
        "        json_paths (List[str]): A list of full paths to the CVAT JSON files.\n",
        "        output_csv_path (str): The full path for the output CSV file.\n",
        "    \"\"\"\n",
        "    all_rows = []\n",
        "\n",
        "    if not json_paths:\n",
        "        print(\"The list of JSON files to process is empty.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(json_paths)} specific files to process.\")\n",
        "\n",
        "    # Process each file and collect the data\n",
        "    for json_path in json_paths:\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f\"Warning: File not found, skipping: {json_path}\")\n",
        "            continue\n",
        "\n",
        "        rows_from_file = process_cvat_json(json_path)\n",
        "\n",
        "        # We assume the first row of each file is a header, so we\n",
        "        # only append the data rows.\n",
        "        if rows_from_file:\n",
        "            all_rows.extend(rows_from_file[1:])\n",
        "\n",
        "    # Prepend the header to the combined data\n",
        "    # if all_rows:\n",
        "    #     header = ['video_name', 'frame_number', 'label', 'x', 'y']\n",
        "    #     all_rows.insert(0, header)\n",
        "\n",
        "    write_csv_data(all_rows, output_csv_path)"
      ],
      "metadata": {
        "id": "zD36-6O1pj5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/FIT3163,3164/SlowFast\"\n",
        "EXPORTS = f\"{ROOT}/03_cvat_exports\"\n",
        "SHOTS = f\"{ROOT}/04_shots/shots.csv\""
      ],
      "metadata": {
        "id": "_37IYHd0uiCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Process ALL files as per Drive structure**"
      ],
      "metadata": {
        "id": "rILPld4Nuo7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Processing all files in the export directory ---\")\n",
        "process_all_cvat_files(EXPORTS, SHOTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2VeXolHunw0",
        "outputId": "dc0e29f8-59e4-4842-d6fd-d90bae125c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing all files in the export directory ---\n",
            "Found 1 files to process.\n",
            "Written 12 rows to /content/drive/MyDrive/FIT3163,3164/SlowFast/04_shots/shots.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Process specific file(s) to separate CSVs**"
      ],
      "metadata": {
        "id": "2Fyu_XjZuztC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = [f\"{EXPORTS}/phua_1/cvat.json\"]\n",
        "output_files = [f\"{ROOT}/04_shots/phua_1.csv\"]\n",
        "assert len(input_files) == len(output_files)\n",
        "\n",
        "for i in range(len(input_files)):\n",
        "    single_file_rows = process_cvat_json(input_files[i])\n",
        "    write_csv_data(single_file_rows, output_files[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P3HdbLDu5TO",
        "outputId": "489a8c79-7d79-462d-d6ea-dcb509f6c351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written 72 rows to /content/drive/MyDrive/FIT3163,3164/SlowFast/04_shots/phua_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Process specific files to one single CSV**"
      ],
      "metadata": {
        "id": "RHOTVFjhpq0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = [\n",
        "    f\"{EXPORTS}/matshi_tanthi_2025/cvat.json\",\n",
        "    f\"{EXPORTS}/sin_tty_2016/cvat.json\",\n",
        "    f\"{EXPORTS}/vitid_anton_2024/cvat.json\"\n",
        "]\n",
        "\n",
        "output_csv = f\"{ROOT}/04_shots/3in1.csv\"\n",
        "\n",
        "print(\"--- Processing a specific list of files into one CSV ---\")\n",
        "process_specific_cvat_files(input_files, output_csv)"
      ],
      "metadata": {
        "id": "cgPpOs7mNhps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a760a316-85d5-439f-96f8-8cfbbdcdf3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing a specific list of files into one CSV ---\n",
            "Found 3 specific files to process.\n",
            "Written 506 rows to /content/drive/MyDrive/FIT3163,3164/SlowFast/04_shots/3in1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJRYtHO8qggm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}